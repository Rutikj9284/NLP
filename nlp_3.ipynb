{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NLP Experiment_03 - Stemming\n",
        "Rutik Jaybhaye\n",
        "Roll No.: 65"
      ],
      "metadata": {
        "id": "ZiDe9dXtrON8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLluCXMCk6fb",
        "outputId": "8a9f0b69-9379-4f12-c73a-a07dc295a916"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porter Stemmer"
      ],
      "metadata": {
        "id": "atcNRUc_mv68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "Port = PorterStemmer()\n"
      ],
      "metadata": {
        "id": "eiNIoEkGmmzE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Snowball Stemmer"
      ],
      "metadata": {
        "id": "iihfx9Mem1PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "Snow = SnowballStemmer(\"english\")\n"
      ],
      "metadata": {
        "id": "ZlMAgMiym5CM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Simplifying words to their most basic form is called stemming, and it is made easier by stemmers or stemming algorithms. For example, “chocolates” becomes “chocolate” and “retrieval” becomes “retrieve.” This is crucial for pipelines for natural language processing, which use tokenized words that are acquired from the first stage of dissecting a document into its constituent words.\""
      ],
      "metadata": {
        "id": "I8w2yqJom_o8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX3-CAcMnxGT",
        "outputId": "0e7648fe-3048-4b6b-e5c0-356073154cad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize words and remove stopwords"
      ],
      "metadata": {
        "id": "GmDF7O5BoRez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove stopwords and punctuation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word not in string.punctuation]\n",
        "\n",
        "words=[]\n",
        "for word in filtered_tokens:\n",
        "  words.append(word)\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDgSKWognNc8",
        "outputId": "d0699e35-93ec-40b9-cadd-3dd01fe7b871"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Simplifying', 'words', 'basic', 'form', 'called', 'stemming', 'made', 'easier', 'stemmers', 'stemming', 'algorithms', 'example', '“', 'chocolates', '”', 'becomes', '“', 'chocolate', '”', '“', 'retrieval', '”', 'becomes', '“', 'retrieve.', '”', 'crucial', 'pipelines', 'natural', 'language', 'processing', 'use', 'tokenized', 'words', 'acquired', 'first', 'stage', 'dissecting', 'document', 'constituent', 'words']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in words:\n",
        "  print(x,':',Snow.stem(x) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0PgFA22oXZS",
        "outputId": "4796eb70-d92c-4093-e1b3-e6a4ca03533b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplifying : simplifi\n",
            "words : word\n",
            "basic : basic\n",
            "form : form\n",
            "called : call\n",
            "stemming : stem\n",
            "made : made\n",
            "easier : easier\n",
            "stemmers : stemmer\n",
            "stemming : stem\n",
            "algorithms : algorithm\n",
            "example : exampl\n",
            "“ : “\n",
            "chocolates : chocol\n",
            "” : ”\n",
            "becomes : becom\n",
            "“ : “\n",
            "chocolate : chocol\n",
            "” : ”\n",
            "“ : “\n",
            "retrieval : retriev\n",
            "” : ”\n",
            "becomes : becom\n",
            "“ : “\n",
            "retrieve. : retrieve.\n",
            "” : ”\n",
            "crucial : crucial\n",
            "pipelines : pipelin\n",
            "natural : natur\n",
            "language : languag\n",
            "processing : process\n",
            "use : use\n",
            "tokenized : token\n",
            "words : word\n",
            "acquired : acquir\n",
            "first : first\n",
            "stage : stage\n",
            "dissecting : dissect\n",
            "document : document\n",
            "constituent : constitu\n",
            "words : word\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in words:\n",
        "  print(x,':',Port.stem(x) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioty1PkEo4W6",
        "outputId": "69ec9ccd-5784-4422-bc24-3cf001f74827"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplifying : simplifi\n",
            "words : word\n",
            "basic : basic\n",
            "form : form\n",
            "called : call\n",
            "stemming : stem\n",
            "made : made\n",
            "easier : easier\n",
            "stemmers : stemmer\n",
            "stemming : stem\n",
            "algorithms : algorithm\n",
            "example : exampl\n",
            "“ : “\n",
            "chocolates : chocol\n",
            "” : ”\n",
            "becomes : becom\n",
            "“ : “\n",
            "chocolate : chocol\n",
            "” : ”\n",
            "“ : “\n",
            "retrieval : retriev\n",
            "” : ”\n",
            "becomes : becom\n",
            "“ : “\n",
            "retrieve. : retrieve.\n",
            "” : ”\n",
            "crucial : crucial\n",
            "pipelines : pipelin\n",
            "natural : natur\n",
            "language : languag\n",
            "processing : process\n",
            "use : use\n",
            "tokenized : token\n",
            "words : word\n",
            "acquired : acquir\n",
            "first : first\n",
            "stage : stage\n",
            "dissecting : dissect\n",
            "document : document\n",
            "constituent : constitu\n",
            "words : word\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy"
      ],
      "metadata": {
        "id": "J42Q-7dG4I3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Provided list of words\n",
        "words = ['building', 'Kullu', 'Himachal', 'Pradesh', 'collapsed', 'swept', 'away', 'fierce', 'currents',\n",
        "         'Parvati', 'River', 'Thursday', 'morning', 'collapse', 'occurred', 'heavy', 'rains', 'caused',\n",
        "         'Parvati', 'River', 'swell', 'increase', 'flow', 'rate', 'exact', 'details', 'building', \"'s\",\n",
        "         'occupancy', 'time', 'collapse', 'yet', 'known']\n",
        "\n",
        "# Define reference stems for comparison (approximate)\n",
        "reference_stems = ['build', 'Kullu', 'Himachal', 'Pradesh', 'collaps', 'swept', 'away', 'fierc', 'current',\n",
        "                    'Parvati', 'River', 'Thursday', 'morn', 'collaps', 'occur', 'heavi', 'rain', 'caus',\n",
        "                    'Parvati', 'River', 'swell', 'increas', 'flow', 'rate', 'exact', 'detail', 'build', 'occup',\n",
        "                    'time', 'collaps', 'yet', 'known']\n",
        "\n",
        "# Initialize counters for correct and total stemmed words\n",
        "correct = 0\n",
        "total = len(words)\n",
        "\n",
        "# Stem each word and compare with the reference\n",
        "for word, ref_stem in zip(words, reference_stems):\n",
        "    # Stem the word\n",
        "    stemmed_word = Port.stem(word)\n",
        "\n",
        "    # Compare the stemmed word with the reference stem\n",
        "    if stemmed_word == ref_stem:\n",
        "        correct += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = correct / total if total > 0 else 0\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuIxQBmg4INP",
        "outputId": "7bc4786a-51fc-4fb2-e8f4-5b92f3b5f569"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Provided list of words\n",
        "words = ['building', 'Kullu', 'Himachal', 'Pradesh', 'collapsed', 'swept', 'away', 'fierce', 'currents',\n",
        "         'Parvati', 'River', 'Thursday', 'morning', 'collapse', 'occurred', 'heavy', 'rains', 'caused',\n",
        "         'Parvati', 'River', 'swell', 'increase', 'flow', 'rate', 'exact', 'details', 'building', \"'s\",\n",
        "         'occupancy', 'time', 'collapse', 'yet', 'known']\n",
        "\n",
        "# Define reference stems for comparison (approximate)\n",
        "reference_stems = ['build', 'Kullu', 'Himachal', 'Pradesh', 'collaps', 'swept', 'away', 'fierc', 'current',\n",
        "                    'Parvati', 'River', 'Thursday', 'morn', 'collaps', 'occur', 'heavi', 'rain', 'caus',\n",
        "                    'Parvati', 'River', 'swell', 'increas', 'flow', 'rate', 'exact', 'detail', 'build', 'occup',\n",
        "                    'time', 'collaps', 'yet', 'known']\n",
        "\n",
        "# Initialize counters for correct and total stemmed words\n",
        "correct = 0\n",
        "total = len(words)\n",
        "\n",
        "# Stem each word and compare with the reference\n",
        "for word, ref_stem in zip(words, reference_stems):\n",
        "    # Stem the word\n",
        "    stemmed_word = Snow.stem(word)\n",
        "\n",
        "    # Compare the stemmed word with the reference stem\n",
        "    if stemmed_word == ref_stem:\n",
        "        correct += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = correct / total if total > 0 else 0\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qUdTcHdZ4W3C",
        "outputId": "d880f022-4b85-4754-b872-23d190296cbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regular expression"
      ],
      "metadata": {
        "id": "D4tGr37Kr2o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "stemmed_words = []\n",
        "for word in words:\n",
        "  # Handle more complex stemming rules\n",
        "  if word.endswith('ies'):\n",
        "    stemmed_word = re.sub(r'(ies)$', 'y', word)\n",
        "  elif word.endswith('ing') or word.endswith('ed') or word.endswith('es') or word.endswith('s'):\n",
        "    stemmed_word = re.sub(r'(ing|ed|es|s)$', '', word)\n",
        "  # Handle words ending in 'y' preceded by a consonant\n",
        "  elif re.search(r'[^aeiou]y$', word):\n",
        "    stemmed_word = re.sub(r'y$', 'i', word)\n",
        "  else:\n",
        "    stemmed_word = word # Keep the word unchanged if no rule applies\n",
        "\n",
        "  stemmed_words.append(stemmed_word)\n",
        "\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUaBJ0Dar2Jy",
        "outputId": "cdca3533-9945-40fc-c77d-a35ffcd664f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['build', 'Kullu', 'Himachal', 'Pradesh', 'collaps', 'swept', 'away', 'fierce', 'current', 'Parvati', 'River', 'Thursday', 'morn', 'collapse', 'occurr', 'heavi', 'rain', 'caus', 'Parvati', 'River', 'swell', 'increase', 'flow', 'rate', 'exact', 'detail', 'build', \"'\", 'occupanci', 'time', 'collapse', 'yet', 'known']\n"
          ]
        }
      ]
    }
  ]
}