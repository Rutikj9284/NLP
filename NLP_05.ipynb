{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDFqN50spILj",
        "outputId": "c4ee9866-af5d-4bf6-e5a1-4f0ee5aa4e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter corpus = i am implementing NLP experiment 5\n",
            "Preprocessed Data corpus = \n",
            " eos i am implementing nlp experiment 5\n",
            "Tokens in the corpus = \n",
            " ['5', 'am', 'nlp', 'experiment', 'eos', 'i', 'implementing']\n",
            "Frequency of each tokens = \n",
            "eos \t: 1\n",
            "i \t: 1\n",
            "am \t: 1\n",
            "implementing \t: 1\n",
            "nlp \t: 1\n",
            "experiment \t: 1\n",
            "5 \t: 1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "d=input(\"Enter corpus = \")\n",
        "def preprocess(d):\n",
        "    d=d.lower()\n",
        "    d=\"eos \"+ d\n",
        "    d=d.replace(\".\",\" eos\")\n",
        "    return d\n",
        "d=preprocess(d)\n",
        "print(\"Preprocessed Data corpus = \\n\",d)\n",
        "from nltk import word_tokenize\n",
        "def generate_tokens(d):\n",
        "    tokens = word_tokenize(d)\n",
        "    return tokens\n",
        "tokens = generate_tokens(d)\n",
        "distinct_tokens = list(set(sorted(tokens)))\n",
        "print(\"Tokens in the corpus = \\n\",distinct_tokens)\n",
        "def generate_tokens_freq(tokens):\n",
        "    dct={}\n",
        "    for i in tokens:\n",
        "        dct[i]=0\n",
        "    for i in tokens:\n",
        "        dct[i]+=1\n",
        "    return dct\n",
        "dct=generate_tokens_freq(tokens)\n",
        "print(\"Frequency of each tokens = \")\n",
        "for i in dct.items():\n",
        "    print(i[0],\"\\t:\" , i[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngrams(tokens,k):\n",
        "    l=[]\n",
        "    i=0\n",
        "    while(i<len(tokens)):\n",
        "        l.append(tokens[i:i+k])\n",
        "        i=i+1\n",
        "    l=l[:-1]\n",
        "    return l\n",
        "bigram = generate_ngrams(tokens,2)\n",
        "print(\"N-grams generated (Here n is 2) = \")\n",
        "for i in bigram:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZCvkS1Gzalc",
        "outputId": "b4138fb2-d73c-4eb6-920e-9c844358fac8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-grams generated (Here n is 2) = \n",
            "['eos', 'i']\n",
            "['i', 'am']\n",
            "['am', 'implementing']\n",
            "['implementing', 'nlp']\n",
            "['nlp', 'experiment']\n",
            "['experiment', '5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ngram_freq(bigram):\n",
        "    dct1={}\n",
        "    for i in bigram:\n",
        "        st=\" \".join(i)\n",
        "        dct1[st]=0\n",
        "    for i in bigram:\n",
        "        st=\" \".join(i)\n",
        "        dct1[st]+=1\n",
        "    return dct1\n",
        "dct1=generate_ngram_freq(bigram)\n",
        "print(\"Frequency of n-grams = \")\n",
        "for i in dct1.items():\n",
        "    print(i[0], \":\", i[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0ByPCDwzgFy",
        "outputId": "7b53713b-f287-42b9-d17d-2a5dd08d6e6a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency of n-grams = \n",
            "eos i : 1\n",
            "i am : 1\n",
            "am implementing : 1\n",
            "implementing nlp : 1\n",
            "nlp experiment : 1\n",
            "experiment 5 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find1(s,dct1):\n",
        "    try:\n",
        "        return dct1[s]\n",
        "    except:\n",
        "        return 0\n",
        "def print_probability_table(distinct_tokens,dct,dct1):\n",
        "    n=len(distinct_tokens)\n",
        "    l=[[]*n for i in range(n)]\n",
        "    for i in range(n):\n",
        "        denominator = dct[distinct_tokens[i]]\n",
        "        for j in range(n):\n",
        "            numerator = find1(distinct_tokens[i]+\" \"+distinct_tokens[j],dct1)\n",
        "            l[i].append(float(\"{:.3f}\".format(numerator/denominator)))\n",
        "    return l\n",
        "print(\"Probability table = \\n\")\n",
        "probability_table=print_probability_table(distinct_tokens,dct,dct1)\n",
        "n=len(distinct_tokens)\n",
        "print(\"\\t\", end=\"\")\n",
        "for i in range(n):\n",
        "    print(distinct_tokens[i],end=\"\\t\")\n",
        "print(\"\\n\")\n",
        "for i in range(n):\n",
        "    print(distinct_tokens[i],end=\"\\t\")\n",
        "    for j in range(n):\n",
        "        print(probability_table[i][j],end=\"\\t\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evIaU6v9zlqK",
        "outputId": "93ebb6c9-ce03-4e56-84e5-5a006886ce99"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability table = \n",
            "\n",
            "\t5\tam\tnlp\texperiment\teos\ti\timplementing\t\n",
            "\n",
            "5\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t\n",
            "\n",
            "am\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t1.0\t\n",
            "\n",
            "nlp\t0.0\t0.0\t0.0\t1.0\t0.0\t0.0\t0.0\t\n",
            "\n",
            "experiment\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t\n",
            "\n",
            "eos\t0.0\t0.0\t0.0\t0.0\t0.0\t1.0\t0.0\t\n",
            "\n",
            "i\t0.0\t1.0\t0.0\t0.0\t0.0\t0.0\t0.0\t\n",
            "\n",
            "implementing\t0.0\t0.0\t1.0\t0.0\t0.0\t0.0\t0.0\t\n",
            "\n"
          ]
        }
      ]
    }
  ]
}